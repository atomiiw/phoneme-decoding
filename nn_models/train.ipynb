{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "629c8e9894f680c6",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9de9524454a74a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:36:37.423150Z",
     "start_time": "2024-07-10T12:36:26.252451Z"
    }
   },
   "outputs": [],
   "source": [
    "# %% Imports\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint, LearningRateMonitor\n",
    "from pytorch_lightning.utilities.model_summary import summarize\n",
    "import torch\n",
    "import numpy as np\n",
    "from data_utils.datamodules import SimpleMicroDataModule, AlignedMicroDataModule\n",
    "from models import CNNTransformer, Transformer, TCN_classifier, TemporalConvRNN, Seq2SeqRNN\n",
    "import data_utils.augmentations as augs\n",
    "import csv\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from alignment import alignment_utils as utils\n",
    "from alignment.AlignCCA import AlignCCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae402b0e2a9fc07",
   "metadata": {},
   "source": [
    "# Define data module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a46a71918adb132d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:36:42.704611Z",
     "start_time": "2024-07-10T12:36:37.423150Z"
    }
   },
   "outputs": [],
   "source": [
    "data_filename = os.path.expanduser('/Users/wangmaidou/Documents/Lang BCI/BCI Code/seq2seq_RNN/pt_decoding_data_S62.pkl')\n",
    "# data_filename = ('../data/pt_decoding_data_S62.pkl')\n",
    "pt_data = utils.load_pkl(data_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "393c11a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['S14', 'S26', 'S23', 'S33', 'S22', 'S39', 'S58', 'S62'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40a38293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ID', 'X1', 'X1_map', 'y1', 'X2', 'X2_map', 'y2', 'X3', 'X3_map', 'y3', 'y_full_phon', 'X_collapsed', 'y_phon_collapsed', 'y_artic_collapsed', 'pre_pts'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_data['S14'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e77a3a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_data['S14']['y_full_phon'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c8e94e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlap between X1 and X2: 170 (corr=0.998)\n",
      "Overlap between X1X2 and X3: 159 (corr=0.998)\n"
     ]
    }
   ],
   "source": [
    "single_trial_single_chan_X1 = pt_data['S14']['X1'][0][:,0]\n",
    "single_trial_single_chan_X2 = pt_data['S14']['X2'][0][:,0]\n",
    "single_trial_single_chan_X3 = pt_data['S14']['X3'][0][:,0]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def find_best_overlap(a, b, min_overlap=20, tol=0.9):\n",
    "    \"\"\"\n",
    "    Find the best overlap length between the end of a and start of b\n",
    "    using correlation. Returns the overlap length and correlation.\n",
    "    \n",
    "    Args:\n",
    "        a, b: numpy arrays (1D sequences)\n",
    "        min_overlap: minimum length of overlap to consider\n",
    "        tol: correlation threshold (0â€“1)\n",
    "    \"\"\"\n",
    "    max_overlap = min(len(a), len(b))\n",
    "    best_corr, best_len = -1, 0\n",
    "\n",
    "    for i in range(min_overlap, max_overlap + 1):\n",
    "        seg_a = a[-i:]\n",
    "        seg_b = b[:i]\n",
    "        corr = np.corrcoef(seg_a, seg_b)[0, 1]\n",
    "        if corr > best_corr:\n",
    "            best_corr, best_len = corr, i\n",
    "\n",
    "    return best_len if best_corr >= tol else 0, best_corr\n",
    "\n",
    "\n",
    "def merge_two(a, b, name_a=\"A\", name_b=\"B\", min_overlap=20, tol=0.9):\n",
    "    \"\"\"\n",
    "    Merge two sequences by finding overlap using correlation.\n",
    "    Returns merged sequence and overlap length.\n",
    "    \"\"\"\n",
    "    overlap_len, corr = find_best_overlap(a, b, min_overlap=min_overlap, tol=tol)\n",
    "    print(f\"Overlap between {name_a} and {name_b}: {overlap_len} (corr={corr:.3f})\")\n",
    "    merged = np.concatenate([a, b[overlap_len:]])\n",
    "    return merged, overlap_len\n",
    "\n",
    "\n",
    "def merge_with_overlap(arrays, names=None, min_overlap=20, tol=0.9):\n",
    "    \"\"\"\n",
    "    Recursively merge a list of sequences by correlation-based overlap.\n",
    "    \"\"\"\n",
    "    if names is None:\n",
    "        names = [f\"X{i+1}\" for i in range(len(arrays))]\n",
    "    if len(arrays) == 1:\n",
    "        return arrays[0], 0\n",
    "    elif len(arrays) == 2:\n",
    "        return merge_two(arrays[0], arrays[1], names[0], names[1], \n",
    "                         min_overlap=min_overlap, tol=tol)\n",
    "    else:\n",
    "        merged_first_two, _ = merge_two(arrays[0], arrays[1], \n",
    "                                        names[0], names[1], \n",
    "                                        min_overlap=min_overlap, tol=tol)\n",
    "        return merge_with_overlap([merged_first_two] + arrays[2:], \n",
    "                                  [names[0] + names[1]] + names[2:], \n",
    "                                  min_overlap=min_overlap, tol=tol)\n",
    "\n",
    "# Example usage\n",
    "merged_signal, overlap_len = merge_with_overlap([\n",
    "    single_trial_single_chan_X1,\n",
    "    single_trial_single_chan_X2,\n",
    "    single_trial_single_chan_X3\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4e2f3ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(3, 3), sharex=True)\n",
    "\n",
    "axs[0].plot(single_trial_single_chan_X1)\n",
    "axs[0].set_title(\"X1\")\n",
    "\n",
    "axs[1].plot(single_trial_single_chan_X2)\n",
    "axs[1].set_title(\"X2\")\n",
    "\n",
    "axs[2].plot(single_trial_single_chan_X3)\n",
    "axs[2].set_title(\"X3\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3362ed91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged signal has length 271.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 1))\n",
    "plt.plot(merged_signal)\n",
    "\n",
    "print(f'Merged signal has length {len(merged_signal)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ced55da2478416b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:36:42.715275Z",
     "start_time": "2024-07-10T12:36:42.704611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(144, 200, 111), (144,), (144, 3)]\n",
      "[[(148, 200, 111), (148,), (148, 3)], [(151, 200, 63), (151,), (151, 3)], [(46, 200, 149), (46,), (46, 3)], [(151, 200, 74), (151,), (151, 3)], [(137, 200, 144), (137,), (137, 3)], [(141, 200, 171), (141,), (141, 3)], [(178, 200, 201), (178,), (178, 3)]]\n"
     ]
    }
   ],
   "source": [
    "pt = 'S14'\n",
    "p_ind = 1\n",
    "lab_type = 'phon'\n",
    "algn_type = 'phon_seq'\n",
    "tar_data, pre_data = utils.decoding_data_from_dict(pt_data, pt, p_ind,\n",
    "                                                   lab_type=lab_type,\n",
    "                                                   algn_type=algn_type)\n",
    "print([d.shape for d in tar_data])\n",
    "print([[d.shape for d in p] for p in pre_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b1fc01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 8, 3, 2, 2, 8, 4, 2, 6, 1, 8, 4, 8, 8, 8, 2, 4, 2, 4, 7, 7, 1,\n",
       "       1, 1, 9, 8, 1, 3, 3, 6, 8, 7, 4, 6, 9, 4, 5, 3, 3, 5, 9, 2, 6, 7,\n",
       "       7, 4, 8, 2, 8, 5, 1, 7, 6, 3, 4, 9, 9, 1, 5, 1, 8, 1, 8, 4, 9, 3,\n",
       "       4, 3, 7, 1, 2, 6, 2, 8, 5, 8, 7, 2, 8, 5, 2, 3, 3, 7, 1, 3, 6, 4,\n",
       "       7, 4, 4, 8, 8, 1, 6, 8, 8, 8, 2, 4, 5, 7, 2, 7, 4, 5, 1, 3, 7, 4,\n",
       "       6, 3, 2, 8, 6, 9, 7, 8, 6, 5, 1, 5, 1, 2, 3, 4, 9, 3, 1, 1, 4, 2,\n",
       "       4, 4, 2, 9, 3, 9, 7, 8, 3, 6, 4, 8], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b30a66092a23064f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:37:23.778265Z",
     "start_time": "2024-07-10T12:36:42.715275Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# dm = SimpleMicroDataModule(data, labels, batch_size=batch_size, folds=n_folds,\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m#                            val_size=val_size, augmentations=augmentations, data_path=os.path.expanduser('~/workspace/transformer_data/pt_specific'))\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m## modification of labels for seq2seq RNN ###\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# #                             batch_size=batch_size, folds=n_folds, val_size=val_size,\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# #                             augmentations=augmentations, data_path=fold_data_path)\u001b[39;00m\n\u001b[32m     38\u001b[39m dm = AlignedMicroDataModule(data, align_labels, align_labels, pool_data, AlignCCA,\n\u001b[32m     39\u001b[39m                             batch_size=batch_size, folds=n_folds, val_size=val_size,\n\u001b[32m     40\u001b[39m                             augmentations=augmentations, data_path=fold_data_path)\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m \u001b[43mdm\u001b[49m\u001b[43m.\u001b[49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Lang BCI/BCI Code/aligned_decoding/nn_models/data_utils/datamodules.py:259\u001b[39m, in \u001b[36mAlignedMicroDataModule.setup\u001b[39m\u001b[34m(self, stage)\u001b[39m\n\u001b[32m    257\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m val_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    258\u001b[39m     val_shape = val_data.shape\n\u001b[32m--> \u001b[39m\u001b[32m259\u001b[39m     val_data = dim_red.transform(\u001b[43mval_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    260\u001b[39m     val_data = torch.Tensor(val_data.reshape(val_shape[\u001b[32m0\u001b[39m], val_shape[\u001b[32m1\u001b[39m], -\u001b[32m1\u001b[39m))\n\u001b[32m    261\u001b[39m test_shape = test_data.shape\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# fold_data_path = '.'\n",
    "\n",
    "fs = 200 # Hz\n",
    "# augmentations = [augs.time_warping, augs.time_masking, augs.time_shifting, augs.noise_jitter, augs.scaling]\n",
    "augmentations = [augs.time_shifting, augs.noise_jitter, augs.scaling]\n",
    "# augmentations = None\n",
    "# data = torch.rand(n_samples, n_timepoints, n_features)\n",
    "# labels = torch.randint(0, 9, (n_samples,))\n",
    "# data = torch.Tensor(all_pt_dict['S14']['X1'])\n",
    "# labels = torch.Tensor(all_pt_dict['S14']['y1']).long() - 1\n",
    "data = torch.Tensor(tar_data[0])\n",
    "labels = torch.Tensor(tar_data[1]).long().unsqueeze(1) - 1\n",
    "align_labels = torch.Tensor(tar_data[2]).long() - 1\n",
    "# pool_data = [(torch.Tensor(p[0]), torch.Tensor(p[1]).long().unsqueeze(1) - 1, torch.Tensor(p[2]).long() - 1) for p in pre_data]\n",
    "pool_data = [(torch.Tensor(p[0]), torch.Tensor(p[2]).long() - 1, torch.Tensor(p[2]).long() - 1) for p in pre_data]  # for seq2seq RNN\n",
    "# data = torch.Tensor(all_pt_dict['S14']['X_collapsed'])\n",
    "# labels = torch.Tensor(all_pt_dict['S14']['y_phon_collapsed']).long() - 1\n",
    "\n",
    "# create the data module\n",
    "batch_size = 500\n",
    "n_folds = 20\n",
    "val_size = 0.1\n",
    "\n",
    "# context_prefix = 'ptSpecific'\n",
    "context_prefix = 'pooled'\n",
    "fold_data_path = os.path.expanduser('/Users/wangmaidou/Documents/Lang BCI/BCI Code/cross_patient_speech_decoding/aligned_decoding/nn_models/RNN folder/') + context_prefix\n",
    "\n",
    "# dm = SimpleMicroDataModule(data, labels, batch_size=batch_size, folds=n_folds,\n",
    "#                            val_size=val_size, augmentations=augmentations, data_path=os.path.expanduser('~/workspace/transformer_data/pt_specific'))\n",
    "## modification of labels for seq2seq RNN ###\n",
    "# dm = SimpleMicroDataModule(data, align_labels, batch_size=batch_size, folds=n_folds,\n",
    "#                            val_size=val_size, augmentations=augmentations, data_path=fold_data_path)\n",
    "\n",
    "\n",
    "# # dm = AlignedMicroDataModule(data, labels, align_labels, pool_data, AlignCCA,\n",
    "# #                             batch_size=batch_size, folds=n_folds, val_size=val_size,\n",
    "# #                             augmentations=augmentations, data_path=fold_data_path)\n",
    "dm = AlignedMicroDataModule(data, align_labels, align_labels, pool_data, AlignCCA,\n",
    "                            batch_size=batch_size, folds=n_folds, val_size=val_size,\n",
    "                            augmentations=augmentations, data_path=fold_data_path)\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "98fad2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4296, 3])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.train_dataloader().dataset.tensors[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1e18287490630e",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ffdeb3bdad199307",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:37:23.785482Z",
     "start_time": "2024-07-10T12:37:23.778265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  | Name          | Type             | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | criterion     | CrossEntropyLoss | 0      | eval \n",
      "1 | temporal_conv | TemporalConv     | 111 K  | train\n",
      "2 | encoder       | EncoderRNN       | 6.3 M  | train\n",
      "3 | decoder       | DecoderRNN       | 1.5 M  | train\n",
      "-----------------------------------------------------------\n",
      "7.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "7.9 M     Total params\n",
      "31.743    Total estimated model params size (MB)\n",
      "11        Modules in train mode\n",
      "1         Modules in eval mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/bci/lib/python3.12/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.utilities.model_summary import summarize\n",
    "\n",
    "\n",
    "gclip_val = 0.5\n",
    "\n",
    "##### CNN TRANSFORMER #####\n",
    "\n",
    "# # model parameters\n",
    "# in_channels = data.shape[-1]\n",
    "# num_classes = 9\n",
    "# d_model = 128\n",
    "# # d_model = data.shape[-1]\n",
    "# kernel_time = 50  # ms\n",
    "# kernel_size = int(kernel_time * fs / 1000)  # kernel length in samples\n",
    "# stride_time = 25  # ms\n",
    "# stride = int(stride_time * fs / 1000)  # stride length in samples\n",
    "# padding = 0\n",
    "# n_head = 8\n",
    "# num_layers = 2\n",
    "# dim_fc = 64\n",
    "# # dim_fc = [128, 256, 128, 64]\n",
    "# cnn_dropout = 0.3\n",
    "# tform_dropout = 0.4\n",
    "# learning_rate = 5e-4\n",
    "# l2_reg = 1e-5\n",
    "# gclip_val = 0.5\n",
    "# activ = True\n",
    "\n",
    "# sum_model = CNNTransformer(in_channels, num_classes, d_model, kernel_size, stride, padding,\n",
    "#                            n_head, num_layers, dim_fc, cnn_dropout, tform_dropout, learning_rate)\n",
    "\n",
    "\n",
    "##### Temporal CNN classifier #####\n",
    "\n",
    "# # model parameters\n",
    "# in_channels = data.shape[-1]\n",
    "# num_classes = 9\n",
    "# kernel_time = 50  # ms\n",
    "# kernel_size = int(kernel_time * fs / 1000)  # kernel length in samples\n",
    "# stride_time = 25  # ms\n",
    "# stride = int(stride_time * fs / 1000)  # stride length in samples\n",
    "# padding = 0\n",
    "# dim_fc = [128, 256, 128, 64]\n",
    "# cnn_dropout = 0.3\n",
    "# learning_rate = 5e-4\n",
    "# l2_reg = 1e-5\n",
    "# gclip_val = 0.5\n",
    "# activ = True\n",
    "\n",
    "# sum_model = TCN_classifier(in_channels, num_classes, dim_fc, kernel_size, stride, padding,\n",
    "#                            cnn_dropout, learning_rate, l2_reg)\n",
    "\n",
    "\n",
    "##### Temporal CNN GRU #####\n",
    "\n",
    "# # model parameters\n",
    "# in_channels = data.shape[-1]\n",
    "# num_classes = 9\n",
    "# n_filters = 100\n",
    "# # d_model = data.shape[-1]\n",
    "# kernel_time = 50  # ms\n",
    "# kernel_size = int(kernel_time * fs / 1000)  # kernel length in samples\n",
    "# stride_time = 25  # ms\n",
    "# stride = int(stride_time * fs / 1000)  # stride length in samples\n",
    "# padding = 0\n",
    "# n_layers = 1\n",
    "# hidden_size = 500\n",
    "# dim_fc = [128, 64]\n",
    "# cnn_dropout = 0.3\n",
    "# rnn_dropout = 0.4\n",
    "# learning_rate = 5e-4\n",
    "# l2_reg = 1e-5\n",
    "# activ = True\n",
    "\n",
    "# sum_model = TemporalConvRNN(in_channels, n_filters, num_classes, hidden_size, n_layers,\n",
    "#                             kernel_size, dim_fc, stride, padding, cnn_dropout,\n",
    "#                             rnn_dropout, learning_rate, l2_reg)\n",
    "\n",
    "\n",
    "\n",
    "##### Seq2Seq RNN #####\n",
    "# model parameters\n",
    "in_channels = data.shape[-1] # 111\n",
    "num_classes = 9\n",
    "n_filters = 100\n",
    "# d_model = data.shape[-1]\n",
    "kernel_time = 50  # ms\n",
    "kernel_size = int(kernel_time * fs / 1000)  # kernel length in samples\n",
    "stride_time = 50  # ms\n",
    "stride = int(stride_time * fs / 1000)  # stride length in samples\n",
    "padding = 0\n",
    "n_enc_layers = 2\n",
    "n_dec_layers = 1\n",
    "hidden_size = 500\n",
    "cnn_dropout = 0.3\n",
    "rnn_dropout = 0.3\n",
    "learning_rate = 1e-4\n",
    "l2_reg = 1e-5\n",
    "activ = False\n",
    "model_type = 'gru'\n",
    "\n",
    "sum_model = Seq2SeqRNN(in_channels, n_filters, hidden_size, num_classes, n_enc_layers,\n",
    "                       n_dec_layers, kernel_size, stride, padding, cnn_dropout,\n",
    "                       rnn_dropout, model_type, learning_rate, l2_reg)\n",
    "\n",
    "print(summarize(sum_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "85622314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad31833df23d804b",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1b5454c4b162770f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:37:24.423208Z",
     "start_time": "2024-07-10T12:37:24.417362Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")\n",
    "warnings.filterwarnings(\"ignore\", \"The number of training batches.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1b1f762b11299743",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:37:24.431450Z",
     "start_time": "2024-07-10T12:37:24.423208Z"
    }
   },
   "outputs": [],
   "source": [
    "# instantiate the trainer\n",
    "max_epochs = 500\n",
    "# es_pat = max_steps // 20\n",
    "# max_steps = 500\n",
    "es_pat = 50\n",
    "warmup = 100\n",
    "# callbacks = [EarlyStopping(monitor='val_loss', patience=10)]\n",
    "log_dir = os.path.expanduser('~/workspace/transformer_data/transformer_logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ddb5ecc37742fee3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-10T12:37:24.439028Z",
     "start_time": "2024-07-10T12:37:24.431450Z"
    }
   },
   "outputs": [],
   "source": [
    "# class MetricCollector(L.Callback):\n",
    "#     def __init__(self):\n",
    "#         self.metrics = {}\n",
    "#     \n",
    "#     def on_validation_epoch_end(self, trainer, pl_module):\n",
    "#         self.metrics['val_loss'] = trainer.logger.metrics['val_loss']\n",
    "#         self.metrics['val_acc'] = trainer.logger.metrics['val_acc']\n",
    "#     \n",
    "#     def on_test_epoch_end(self, trainer, pl_module):\n",
    "#         self.metrics['test_loss'] = trainer.logger.metrics['test_loss']\n",
    "#         self.metrics['test_acc'] = trainer.logger.metrics['test_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d553c30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional.classification import multiclass_confusion_matrix\n",
    "\n",
    "def cmat_acc(y_hat, y, num_classes):\n",
    "    y_pred = torch.argmax(y_hat, dim=1)\n",
    "    cmat = multiclass_confusion_matrix(y_pred, y, num_classes)\n",
    "    acc_cmat = cmat.diag().sum() / cmat.sum()\n",
    "    return acc_cmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "30910d8dbfaa0aa8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-07-10T12:37:24.440539Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Setting up data module for iteration 1 #####\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/bci/lib/python3.12/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bci/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:47\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     46\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bci/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:575\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    569\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    570\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    571\u001b[39m     ckpt_path,\n\u001b[32m    572\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    573\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    574\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m575\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    577\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bci/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:982\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m    979\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m    980\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m    981\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m982\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m    985\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m    986\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bci/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:1026\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.autograd.set_detect_anomaly(\u001b[38;5;28mself\u001b[39m._detect_anomaly):\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bci/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:216\u001b[39m, in \u001b[36m_FitLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28mself\u001b[39m.on_advance_start()\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28mself\u001b[39m.on_advance_end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bci/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:455\u001b[39m, in \u001b[36m_FitLoop.advance\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepoch_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bci/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py:150\u001b[39m, in \u001b[36m_TrainingEpochLoop.run\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_advance_end(data_fetcher)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bci/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py:320\u001b[39m, in \u001b[36m_TrainingEpochLoop.advance\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer.lightning_module.automatic_optimization:\n\u001b[32m    319\u001b[39m     \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m320\u001b[39m     batch_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mautomatic_optimization\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bci/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py:192\u001b[39m, in \u001b[36m_AutomaticOptimization.run\u001b[39m\u001b[34m(self, optimizer, batch_idx, kwargs)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[32m    190\u001b[39m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[32m    191\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    194\u001b[39m result = closure.consume_result()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bci/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py:270\u001b[39m, in \u001b[36m_AutomaticOptimization._optimizer_step\u001b[39m\u001b[34m(self, batch_idx, train_step_and_backward_closure)\u001b[39m\n\u001b[32m    269\u001b[39m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moptimizer_step\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bci/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:171\u001b[39m, in \u001b[36m_call_lightning_module_hook\u001b[39m\u001b[34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m     output = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bci/lib/python3.12/site-packages/lightning/pytorch/core/module.py:1302\u001b[39m, in \u001b[36mLightningModule.optimizer_step\u001b[39m\u001b[34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[39m\n\u001b[32m   1278\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Override this method to adjust the default way the :class:`~lightning.pytorch.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[32m   1279\u001b[39m \u001b[33;03mthe optimizer.\u001b[39;00m\n\u001b[32m   1280\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1300\u001b[39m \n\u001b[32m   1301\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1302\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bci/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py:154\u001b[39m, in \u001b[36mLightningOptimizer.step\u001b[39m\u001b[34m(self, closure, **kwargs)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_strategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[38;5;28mself\u001b[39m._on_after_step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bci/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py:239\u001b[39m, in \u001b[36mStrategy.optimizer_step\u001b[39m\u001b[34m(self, optimizer, closure, model, **kwargs)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl.LightningModule)\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprecision_plugin\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bci/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py:123\u001b[39m, in \u001b[36mPrecision.optimizer_step\u001b[39m\u001b[34m(self, optimizer, model, closure, **kwargs)\u001b[39m\n\u001b[32m    122\u001b[39m closure = partial(\u001b[38;5;28mself\u001b[39m._wrap_closure, model, optimizer, closure)\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bci/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:137\u001b[39m, in \u001b[36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    136\u001b[39m opt._opt_called = \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bci/lib/python3.12/site-packages/torch/optim/optimizer.py:487\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    483\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    484\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    485\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m487\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bci/lib/python3.12/site-packages/torch/optim/optimizer.py:91\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     90\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bci/lib/python3.12/site-packages/torch/optim/adamw.py:197\u001b[39m, in \u001b[36mAdamW.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.enable_grad():\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m         loss = \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.param_groups:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bci/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py:109\u001b[39m, in \u001b[36mPrecision._wrap_closure\u001b[39m\u001b[34m(self, model, optimizer, closure)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[33;03mhook is called.\u001b[39;00m\n\u001b[32m    104\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    107\u001b[39m \n\u001b[32m    108\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m closure_result = \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[38;5;28mself\u001b[39m._after_closure(model, optimizer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bci/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py:146\u001b[39m, in \u001b[36mClosure.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    144\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> Optional[Tensor]:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m     \u001b[38;5;28mself\u001b[39m._result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result.loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bci/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bci/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py:131\u001b[39m, in \u001b[36mClosure.closure\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;129m@torch\u001b[39m.enable_grad()\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mclosure\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args: Any, **kwargs: Any) -> ClosureResult:\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     step_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_step_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    133\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m step_output.closure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bci/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py:319\u001b[39m, in \u001b[36m_AutomaticOptimization._training_step\u001b[39m\u001b[34m(self, kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m trainer = \u001b[38;5;28mself\u001b[39m.trainer\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m training_step_output = \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtraining_step\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[38;5;28mself\u001b[39m.trainer.strategy.post_training_step()  \u001b[38;5;66;03m# unused hook - call anyway for backward compatibility\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bci/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:323\u001b[39m, in \u001b[36m_call_strategy_hook\u001b[39m\u001b[34m(trainer, hook_name, *args, **kwargs)\u001b[39m\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer.strategy.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m323\u001b[39m     output = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bci/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py:391\u001b[39m, in \u001b[36mStrategy.training_step\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    390\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_redirection(\u001b[38;5;28mself\u001b[39m.model, \u001b[38;5;28mself\u001b[39m.lightning_module, \u001b[33m\"\u001b[39m\u001b[33mtraining_step\u001b[39m\u001b[33m\"\u001b[39m, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m391\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlightning_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Lang BCI/BCI Code/cross_patient_speech_decoding/aligned_decoding/nn_models/models.py:172\u001b[39m, in \u001b[36mSeq2SeqRNN.training_step\u001b[39m\u001b[34m(self, batch, batch_idx)\u001b[39m\n\u001b[32m    171\u001b[39m \u001b[38;5;66;03m# use teacher forcing during training\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m y_hat = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteacher_forcing_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (batch_size, seq_length, num_classes)\u001b[39;00m\n\u001b[32m    173\u001b[39m y_hat = y_hat.view(-\u001b[32m1\u001b[39m, \u001b[38;5;28mself\u001b[39m.num_classes)  \u001b[38;5;66;03m# (batch_size*seq_length, num_classes)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bci/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bci/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Lang BCI/BCI Code/cross_patient_speech_decoding/aligned_decoding/nn_models/models.py:149\u001b[39m, in \u001b[36mSeq2SeqRNN.forward\u001b[39m\u001b[34m(self, x, y, teacher_forcing_ratio)\u001b[39m\n\u001b[32m    148\u001b[39m batch_size = x.size(\u001b[32m0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m start_tokens = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfull\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlong\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m dec_input = start_tokens\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 53\u001b[39m\n\u001b[32m     42\u001b[39m trainer = L.Trainer(default_root_dir=log_dir,\n\u001b[32m     43\u001b[39m                     max_epochs=max_epochs,\n\u001b[32m     44\u001b[39m                     \u001b[38;5;66;03m# max_steps=max_steps,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     50\u001b[39m                     enable_progress_bar=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     51\u001b[39m                    )\n\u001b[32m     52\u001b[39m \u001b[38;5;66;03m# # trainer.fit(model, dm)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[38;5;28mprint\u001b[39m(trainer.logged_metrics)\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# print(trainer.callback_metrics)\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# print the training metrics from the best model checkpoint\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# print(f'Fold {fold} best model metrics:')\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# trainer.test(model, dm)\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# model = CNNTransformer.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bci/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:539\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28mself\u001b[39m.state.status = TrainerStatus.RUNNING\n\u001b[32m    538\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m539\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    540\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    541\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bci/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:64\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[32m     63\u001b[39m         launcher.kill(_get_sigkill_signal())\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     \u001b[43mexit\u001b[49m(\u001b[32m1\u001b[39m)\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[32m     67\u001b[39m     _interrupt(trainer, exception)\n",
      "\u001b[31mNameError\u001b[39m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "acc_dir = os.path.expanduser('~/workspace/transformer_data/accs/')\n",
    "\n",
    "# train the model\n",
    "n_iters = 20\n",
    "iter_accs = []\n",
    "for i in range(n_iters):\n",
    "    print(f'##### Setting up data module for iteration {i+1} #####')\n",
    "    dm.setup()\n",
    "    \n",
    "    fold_accs = []\n",
    "    # y_pred_all = []\n",
    "    # y_test_all = []\n",
    "    for fold in range(n_folds):\n",
    "        # if fold > 1:\n",
    "        #     break\n",
    "        dm.set_fold(fold)\n",
    "        # print(dm.current_fold)\n",
    "        \n",
    "        # instantiate the model\n",
    "        in_channels = dm.get_data_shape()[-1]\n",
    "        # print(in_channels)\n",
    "        # model = CNNTransformer(in_channels, num_classes, d_model, kernel_size, stride, padding,\n",
    "        #                        n_head, num_layers, dim_fc, cnn_dropout, tform_dropout, learning_rate,\n",
    "        #                        warmup, max_steps, l2_reg, activation=activ)\n",
    "        # model = TCN_classifier(in_channels, num_classes, dim_fc, kernel_size, stride, padding,\n",
    "        #                            cnn_dropout, learning_rate, l2_reg, activation=activ)\n",
    "        # model = TemporalConvRNN(in_channels, n_filters, num_classes, hidden_size, n_layers,\n",
    "                                # kernel_size, dim_fc, stride, padding, cnn_dropout,\n",
    "                                # rnn_dropout, learning_rate, l2_reg, activation=activ,\n",
    "                                # decay_iters=max_epochs)\n",
    "        model = Seq2SeqRNN(in_channels, n_filters, hidden_size, num_classes, n_enc_layers,\n",
    "                           n_dec_layers, kernel_size, stride, padding, cnn_dropout, rnn_dropout, model_type,\n",
    "                           learning_rate, l2_reg, activation=activ, decay_iters=max_epochs)\n",
    "        \n",
    "        # model.current_fold = fold\n",
    "        callbacks = [\n",
    "            # ModelCheckpoint(monitor='val_loss', mode='min'),\n",
    "            ModelCheckpoint(monitor='val_acc', mode='max'),\n",
    "            # EarlyStopping(monitor='val_loss', patience=es_pat),\n",
    "            LearningRateMonitor(logging_interval='epoch'),\n",
    "            ]\n",
    "        trainer = L.Trainer(default_root_dir=log_dir,\n",
    "                            max_epochs=max_epochs,\n",
    "                            # max_steps=max_steps,\n",
    "                            gradient_clip_val=gclip_val,\n",
    "                            accelerator='auto',\n",
    "                            callbacks=callbacks,\n",
    "                            logger=True,\n",
    "                            enable_model_summary=False,\n",
    "                            enable_progress_bar=False,\n",
    "                           )\n",
    "        # # trainer.fit(model, dm)\n",
    "        trainer.fit(model=model, train_dataloaders=dm.train_dataloader(), val_dataloaders=dm.val_dataloader())\n",
    "        print(trainer.logged_metrics)\n",
    "        # print(trainer.callback_metrics)\n",
    "        # print the training metrics from the best model checkpoint\n",
    "        # print(f'Fold {fold} best model metrics:')\n",
    "        # print(trainer.checkpoint_callback.best_model_score)\n",
    "\n",
    "\n",
    "        # trainer.test(model, dm)\n",
    "        # model = CNNTransformer.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
    "        trainer.test(model=model, dataloaders=dm.test_dataloader(), ckpt_path='best')\n",
    "        # trainer.test(dataloaders=dm.test_dataloader(), ckpt_path='best')\n",
    "\n",
    "        # test_pred = model(dm.test_dataloader().dataset.tensors[0])\n",
    "        # test_pred = trainer.predict(model, dm.test_dataloader(), ckpt_path='best)[0]\n",
    "        # test_pred = torch.argmax(test_pred, dim=1)\n",
    "        # print(test_pred)\n",
    "        # y_pred_all.extend(test_pred)\n",
    "        # y_test_all.extend(dm.test_dataloader().dataset.tensors[1])\n",
    "        \n",
    "        fold_accs.append(trainer.logged_metrics['test_acc'])\n",
    "    \n",
    "        # save loss information\n",
    "        # loss_dict = trainer.logger.metrics\n",
    "        # loss_dict['fold'] = fold\n",
    "        # loss_dict['model'] = model\n",
    "    # acc = cmat_acc(torch.stack(y_pred_all), torch.stack(y_test_all), num_classes)\n",
    "    # print(acc)\n",
    "    # iter_accs.append(acc)\n",
    "    # print(f'Averaged accuracy: {sum(fold_accs) / len(fold_accs)}')\n",
    "    iter_accs.append(fold_accs)\n",
    "    with open(os.path.join(acc_dir, f'{context_prefix}/{pt}_{context_prefix}_seq2seq_rnn_accs_iter{i+1}.csv'), 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(iter_accs)\n",
    "    print(np.mean(fold_accs))\n",
    "# print(sum(iter_accs) / len(iter_accs), iter_accs)\n",
    "print(iter_accs)\n",
    "with open(os.path.join(acc_dir, f'{context_prefix}/{pt}_{context_prefix}_seq2seq_rnn_accs.csv'), 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(iter_accs)\n",
    "np.save(os.path.join(acc_dir, f'{context_prefix}/{pt}_{context_prefix}_seq2seq_rnn_accs.npy'), np.array(iter_accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93686a0",
   "metadata": {},
   "source": [
    "# View results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4f2348ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = 'S14'\n",
    "acc_dir = os.path.expanduser('~/workspace/transformer_data/accs/')\n",
    "context_prefix = 'pooled'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1e334142",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/wangmaidou/workspace/transformer_data/accs/pooled/S14_pooled_seq2seq_rnn_accs.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m iter_accs = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43macc_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcontext_prefix\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpt\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcontext_prefix\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m_seq2seq_rnn_accs.npy\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(iter_accs.shape)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(iter_accs.mean(axis=\u001b[32m1\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/bci/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:454\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[39m\n\u001b[32m    452\u001b[39m     own_fid = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m454\u001b[39m     fid = stack.enter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m    455\u001b[39m     own_fid = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    457\u001b[39m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/Users/wangmaidou/workspace/transformer_data/accs/pooled/S14_pooled_seq2seq_rnn_accs.npy'"
     ]
    }
   ],
   "source": [
    "iter_accs = np.load(os.path.join(acc_dir, f'{context_prefix}/{pt}_{context_prefix}_seq2seq_rnn_accs.npy'))\n",
    "print(iter_accs.shape)\n",
    "print(iter_accs.mean(axis=1))\n",
    "print(iter_accs.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9b87d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# from torch import tensor\n",
    "# test = [[tensor(0.5000), tensor(0.3636), tensor(0.2727), tensor(0.4545), tensor(0.3182), tensor(0.4545), tensor(0.4091), tensor(0.2273), tensor(0.2727), tensor(0.4091), tensor(0.2727), tensor(0.3182), tensor(0.3333), tensor(0.3333), tensor(0.4762), tensor(0.3333), tensor(0.2857), tensor(0.3810), tensor(0.3810), tensor(0.3810)]]\n",
    "# plt.boxplot(iter_accs.mean(axis=1))\n",
    "sns.boxplot(data=iter_accs.mean(axis=1))\n",
    "sns.swarmplot(data=iter_accs.mean(axis=1), color='black')\n",
    "# sns.boxplot(data=iter_accs.T)\n",
    "# sns.swarmplot(data=iter_accs.T, color='black')\n",
    "plt.axhline(y=1/9, color='gray', linestyle='--')\n",
    "plt.ylim(0, None)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
