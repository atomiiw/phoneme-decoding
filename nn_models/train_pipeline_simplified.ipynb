{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59a82135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import csv\n",
    "import numpy as np\n",
    "import lightning as L\n",
    "import data_utils.augmentations as augs\n",
    "from data_utils.datamodules import AlignedMicroDataModule\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from alignment import alignment_utils as utils\n",
    "from alignment.AlignCCA import AlignCCA\n",
    "from models import Seq2SeqRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8758723",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13cc9406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def folds_exist(path, n_folds):\n",
    "    for i in range(n_folds):\n",
    "        f = os.path.join(path, f\"fold_data/fold_{i}.h5\")\n",
    "        if not os.path.exists(f):\n",
    "            print(\"❌ Missing:\", f)\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2068824f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/pt_decoding_data_S62.pkl'\n",
    "fold_data_path = '../data/training_data_pooled'\n",
    "patient_id = 'S14' # Training on S14's data.\n",
    "batch_size = 500\n",
    "n_folds = 20\n",
    "val_size = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e484a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filename = os.path.expanduser(data_path)\n",
    "pt_data = utils.load_pkl(data_filename)\n",
    "\n",
    "phoneme_index = 1 # All samples center around phoneme 1 onset.\n",
    "lab_type = 'phon'\n",
    "algn_type = 'phon_seq'\n",
    "tar_data, pre_data = utils.decoding_data_from_dict(pt_data, patient_id, phoneme_index,\n",
    "                                                   lab_type=lab_type,\n",
    "                                                   algn_type=algn_type)\n",
    "# tar_data = X1, y1, [y1, y2, y3], on the target patient\n",
    "# pre_data = 7 * tar_data, on the 7 non-target patients\n",
    "# pre_data is not used at all in training\n",
    "\n",
    "augmentations = [augs.time_shifting, augs.noise_jitter, augs.scaling]\n",
    "data = torch.Tensor(tar_data[0])\n",
    "labels = torch.Tensor(tar_data[1]).long().unsqueeze(1) - 1\n",
    "align_labels = torch.Tensor(tar_data[2]).long() - 1\n",
    "pool_data = [(torch.Tensor(p[0]), torch.Tensor(p[2]).long() - 1, torch.Tensor(p[2]).long() - 1) for p in pre_data] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2a9ebca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All folds found, reusing existing DataModule...\n"
     ]
    }
   ],
   "source": [
    "if folds_exist(fold_data_path, n_folds):\n",
    "    print(\"✅ All folds found, reusing existing DataModule...\")\n",
    "    dm = AlignedMicroDataModule(\n",
    "        data, align_labels, align_labels, pool_data, AlignCCA,\n",
    "        batch_size=batch_size, folds=n_folds, val_size=val_size,\n",
    "        augmentations=augmentations, data_path=fold_data_path\n",
    "    )\n",
    "else:\n",
    "    print(\"⚙️ Generating new folds...\")\n",
    "    dm = AlignedMicroDataModule(\n",
    "        data, align_labels, align_labels, pool_data, AlignCCA,\n",
    "        batch_size=batch_size, folds=n_folds, val_size=val_size,\n",
    "        augmentations=augmentations, data_path=fold_data_path\n",
    "    )\n",
    "    dm.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802387c6",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "933d508c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([144, 200, 111])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba70dfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gclip_val = 0.5\n",
    "fs = 200\n",
    "in_channels = data.shape[-1] # 111\n",
    "num_classes = 9\n",
    "kernel_time = 50  # ms\n",
    "kernel_size = int(kernel_time * fs / 1000)  # kernel length in samples\n",
    "stride_time = 50  # ms\n",
    "stride = int(stride_time * fs / 1000)  # stride length in samples\n",
    "padding = 0\n",
    "n_enc_layers = 2\n",
    "n_dec_layers = 1\n",
    "activ = False\n",
    "model_type = 'gru'\n",
    "\n",
    "max_epochs = 500\n",
    "log_dir = os.path.join(\"..\", \"data\", \"transformer_logs\")\n",
    "context_prefix = \"pooled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "587c8a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_filters = 100\n",
    "hidden_size = 500\n",
    "cnn_dropout = 0.3\n",
    "rnn_dropout = 0.3\n",
    "learning_rate = 1e-4\n",
    "l2_reg = 1e-5\n",
    "n_iters = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47ce5c0",
   "metadata": {},
   "source": [
    "**Model Architecture:**\n",
    "\n",
    "1. Temporal Conv:\n",
    "    - Input: 200 timesteps * 111 features\n",
    "    - Output: 20 timesteps * 100 features\n",
    "    - kernel (10 timesteps * 111 features) * 100 different versions of kernel\n",
    "2. Encoder:\n",
    "    - Input: 20 tokens * 100-dim vector per token\n",
    "    - Output: h_20, a 500-dim vector\n",
    "    - h_t = GRU(h_t-1, x_t)\n",
    "        * t = 20 tokens\n",
    "        * x_t = one token of 100-dim (features representing the current chunk of time)\n",
    "        * h_t = hidden state of 500-dim (a new set of features to represent the current + prev chunk of time)\n",
    "3. Decoder:\n",
    "    - Input: encoder's output, a 500-dim vector encoding the whole sequence\n",
    "    - Output: y_1, y_2, y_3, 3 classification results\n",
    "    - h_t = GRU(h_t-1, x_t)\n",
    "        * t = 3, each producing 1 phoneme prediction\n",
    "        * h_t = hidden state of 500-dim (features representing current chunk of time + previous phon prediction)\n",
    "        * x_t = a 500-dim representation of the predicted phon (x_0 = a sequence for class 0 \"SOS\")\n",
    "    - y_t = integer in 0-8 = a_simple_proj(h_t)\n",
    "    - x_t+1 = Embedding(y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38b8e17f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_iters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m acc_dir = os.path.join(\u001b[33m\"\u001b[39m\u001b[33m..\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33maccuracy_data_post_training\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m iter_accs = []  \u001b[38;5;66;03m# store all accuracies across iterations\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mn_iters\u001b[49m):\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m##### Setting up data module for iteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m #####\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      7\u001b[39m     dm.setup()  \u001b[38;5;66;03m# prepare dataset (splits, etc.)\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'n_iters' is not defined"
     ]
    }
   ],
   "source": [
    "# specify a folder to save all accuracy data\n",
    "acc_dir = os.path.join(\"..\", \"data\", \"accuracy_data_post_training\")\n",
    "iter_accs = []  # store all accuracies across iterations\n",
    "\n",
    "for i in range(n_iters):\n",
    "    print(f'##### Setting up data module for iteration {i+1} #####')\n",
    "    dm.setup()  # prepare dataset (splits, etc.)\n",
    "    \n",
    "    fold_accs = []  # store results for this iteration’s folds\n",
    "\n",
    "    # go through each fold\n",
    "    for fold in range(n_folds):\n",
    "        dm.set_fold(fold)\n",
    "        in_channels = dm.get_data_shape()[-1]  # number of input features (111 channels)\n",
    "\n",
    "        # build a fresh Seq2SeqRNN for this fold\n",
    "        model = Seq2SeqRNN(in_channels, n_filters, hidden_size, num_classes, n_enc_layers,\n",
    "                           n_dec_layers, kernel_size, stride, padding, cnn_dropout, rnn_dropout, model_type,\n",
    "                           learning_rate, l2_reg, activation=activ, decay_iters=max_epochs)\n",
    "\n",
    "        # callbacks: save best model + log learning rate\n",
    "        callbacks = [\n",
    "            ModelCheckpoint(monitor='val_acc', mode='max'),\n",
    "            LearningRateMonitor(logging_interval='epoch'),\n",
    "        ]\n",
    "\n",
    "        # trainer controls training loop\n",
    "        trainer = L.Trainer(default_root_dir=log_dir,\n",
    "                            max_epochs=max_epochs,\n",
    "                            gradient_clip_val=gclip_val,   # prevent exploding gradients\n",
    "                            accelerator='auto',            # GPU if available\n",
    "                            callbacks=callbacks,\n",
    "                            logger=True,\n",
    "                            enable_model_summary=False,\n",
    "                            enable_progress_bar=False)\n",
    "\n",
    "        # train and validate for all epochs\n",
    "        trainer.fit(model=model, \n",
    "                    train_dataloaders=dm.train_dataloader(), \n",
    "                    val_dataloaders=dm.val_dataloader())\n",
    "\n",
    "        # print training/validation metrics\n",
    "        print(trainer.logged_metrics)\n",
    "\n",
    "        # take the epoch with the best validation checkpoint, test it\n",
    "        trainer.test(model=model, \n",
    "                     dataloaders=dm.test_dataloader(), \n",
    "                     ckpt_path='best')\n",
    "\n",
    "        # store test accuracy for this fold (just one number)\n",
    "        fold_accs.append(trainer.logged_metrics['test_acc'])\n",
    "    \n",
    "    # store fold accuracies for this iteration (n_fold numbers)\n",
    "    iter_accs.append(fold_accs)\n",
    "\n",
    "    # ensure save folder exists\n",
    "    os.makedirs(os.path.join(acc_dir, context_prefix), exist_ok=True)\n",
    "\n",
    "    # save partial results (up to this iteration) as CSV\n",
    "    with open(os.path.join(acc_dir, f\"{context_prefix}/{patient_id}_{context_prefix}_seq2seq_rnn_accs_iter{i+1}.csv\"), 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(iter_accs)\n",
    "\n",
    "    # print average accuracy across folds for this iteration\n",
    "    print(np.mean(fold_accs))\n",
    "\n",
    "# after all iterations: save final results\n",
    "print(iter_accs)\n",
    "\n",
    "# save all accuracies into one CSV\n",
    "with open(os.path.join(acc_dir, f\"{context_prefix}/{patient_id}_{context_prefix}_seq2seq_rnn_accs.csv\"), 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(iter_accs)\n",
    "\n",
    "# also save as .npy (easy reload in Python)\n",
    "np.save(os.path.join(acc_dir, f\"{context_prefix}/{patient_id}_{context_prefix}_seq2seq_rnn_accs.npy\"),\n",
    "        np.array(iter_accs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
